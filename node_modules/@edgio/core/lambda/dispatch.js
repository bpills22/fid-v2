"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.dispatch = void 0;
require("./global.helpers");
const LambdaRequest_1 = __importDefault(require("../runtime/LambdaRequest"));
const LambdaResponse_1 = __importDefault(require("../runtime/LambdaResponse"));
const RequestHandler_1 = __importDefault(require("../runtime/RequestHandler"));
const PropertyContext_1 = __importDefault(require("../runtime/PropertyContext"));
const constants_1 = require("../constants");
const errors_1 = require("../errors");
const log_1 = __importDefault(require("../log"));
const stdStreamsWrapper_1 = __importStar(require("./injection/stdStreamsWrapper"));
const getBodyLoggingData_1 = __importDefault(require("./injection/getBodyLoggingData"));
const RuntimeContext_1 = require("./RuntimeContext");
const environment_1 = require("../environment");
const serverMetrics_1 = require("./serverMetrics");
const EdgioProjectRequestLoopError_1 = require("../errors/EdgioProjectRequestLoopError");
const dispatch = async (nodeReq, nodeRes) => {
    var _a, _b, _c, _d;
    const req = await LambdaRequest_1.default.fromNodeRequest(nodeReq);
    const res = LambdaResponse_1.default.fromNodeResponse(nodeRes);
    let runtime;
    let objects;
    try {
        // Get/initialize the runtime context and wait for it to be ready before we can process the request.
        // At this place where first request comes in, the runtime should be already initialized,
        // as server initializes the runtime right after it starts listening.
        runtime = (0, RuntimeContext_1.getRuntime)();
        objects = await runtime.waitForRuntime();
        // Start Deep Request Inspection logging if enabled
        if ((_a = runtime.runtimeOptions) === null || _a === void 0 ? void 0 : _a.driLogging) {
            startLogging(req);
        }
        // Detect and throw an error if there's a loop in the request path.
        // For example when site is fetching itself multiple times in compute using fetch function.
        detectUpstreamRequestLoop(req);
        await dispatchRequest(req, res, objects);
    }
    catch (e) {
        serverMetrics_1.metrics.serverErrorCount++;
        // Here we catch all project-level errors (Error Level: 2)
        // and render nice looking error page with error details.
        // ERROR LEVELS overview:
        // Error Level 0 is handled by the Edge and means that both lambdas failed or are not available.
        // Error Level 1 is handled by the Lambda itself and is for fatal server errors, like timeouts, out of memory etc...
        // Error Level 2 is handled by the Lambda itself and is for project errors, like uncaught user-errors in compute, malformed responses, etc...
        // Wrap all errors into EdgioError instance
        const error = (0, errors_1.isEdgioError)(e) ? e : new errors_1.EdgioProjectError(e.message, e.stack);
        // We need to clear any current chunks.
        // They could be there if error happens during proxy, computes, and other stuff that doesn't stream.
        res.clear();
        res.clearHeaders();
        res.setIsStreamable(false);
        const type = ((_b = req.getHeader(constants_1.HTTP_HEADERS.accept)) === null || _b === void 0 ? void 0 : _b.toString().includes('html')) ? 'html' : 'json';
        const requestId = (_c = req.getHeader(constants_1.HTTP_HEADERS.xEcUUID)) === null || _c === void 0 ? void 0 : _c.toString();
        const requestSource = req.invokeSource;
        // Log the error for debugging
        log_1.default.error(`[Edgio Error][Level 2]: ${req.method} ${req.url} - ${e.stack}`);
        // Render the EdgioError to HTML or JSON response
        res.statusCode = error.statusCode;
        res.statusMessage = error.statusMessage;
        res.setHeader(constants_1.HTTP_HEADERS.contentType, type === 'html' ? 'text/html' : 'application/json');
        res.setHeader(constants_1.HTTP_HEADERS.xEdgErrorMessage, encodeURI(error.message));
        res.setHeader(constants_1.HTTP_HEADERS.xEdgErrorLevel, error.level.toString());
        res.setHeader(constants_1.HTTP_HEADERS.xEdgErrorDetails, encodeURI(error.details || ''));
        res.body = error.render({
            type,
            requestId,
            includeStack: (0, environment_1.isLocal)() || requestSource === constants_1.INVOKE_SOURCES.console,
        });
    }
    finally {
        // Stop Deep Request Inspection logging if enabled
        if ((_d = runtime === null || runtime === void 0 ? void 0 : runtime.runtimeOptions) === null || _d === void 0 ? void 0 : _d.driLogging) {
            stopLogging(res);
        }
        // If catch top-level error,
        // we still need to end the response and stream it
        await res.end();
        res.stream();
        await res.waitForFlush();
    }
};
exports.dispatch = dispatch;
const dispatchRequest = async (req, res, objects) => {
    // THIS IS IMPORTANT!
    // The invokeAction for the edge_control config is accepted only from the console-api.
    // Otherwise, any could request the edge_control config through the Function URL
    // and this would be a security issue.
    if (req.invokeSource === constants_1.INVOKE_SOURCES.console) {
        if (req.invokeAction === constants_1.INVOKE_ACTIONS.getEdgeConfig) {
            return new PropertyContext_1.default(objects.configForEdge)
                .createEdgeConfig(objects.router)
                .writeToStream(res);
        }
        if (req.invokeAction === constants_1.INVOKE_ACTIONS.getPreloadConfig) {
            return (await objects.router.preloadRequests.getPreloadConfig(objects.config)).writeToStream(res);
        }
    }
    const requestHandler = new RequestHandler_1.default(objects);
    if (req.invokeAction === constants_1.INVOKE_ACTIONS.serverless) {
        return await requestHandler.handleServerless(req, res);
    }
    return await requestHandler.handleSimulator(req, res);
};
/**
 * Starts collecting stdout, stderr and other streams
 * and logs the incoming request
 * @param req The inconcoming request
 */
function startLogging(req) {
    var _a, _b;
    const driLogger = (0, stdStreamsWrapper_1.deepRequestInspectionLogger)();
    // Enable logging of all std streams
    stdStreamsWrapper_1.default.enable({
        clientIp: req.socket.remoteAddress,
        requestId: (_a = req.getHeader(constants_1.HTTP_HEADERS.xEcUUID)) === null || _a === void 0 ? void 0 : _a.toString(),
    });
    // Log incoming request
    driLogger.logDownstreamRequestInfo({
        method: req.method,
        path: req.url,
        host: (_b = req.getHeader(constants_1.HTTP_HEADERS.host)) === null || _b === void 0 ? void 0 : _b.toString(),
        headers: req.getHeaders(),
        // We keep the protocol format same as the internal Node format on protocol fields.
        protocol: `${req.protocol}:`,
        ...(0, getBodyLoggingData_1.default)(req.body, req.getHeaders()),
    });
}
/**
 * Stops collecting stdout
 * and logs the outgoing response
 * @param res The outgoing response
 */
function stopLogging(res) {
    const driLogger = (0, stdStreamsWrapper_1.deepRequestInspectionLogger)();
    const resBody = res.chunks.length > 0 ? res.chunks : res.body;
    // Log outgoing response
    driLogger.logDownstreamResponseInfo({
        statusCode: res.statusCode,
        statusMessage: res.statusMessage,
        headers: res.getHeaders(),
        ...(0, getBodyLoggingData_1.default)(resBody, res.getHeaders()),
    });
    // Disable logging of all std streams
    stdStreamsWrapper_1.default.disable();
}
/**
 * Captures the path of the current request
 * and throws an error if it detects a loop.
 * For example when site is fetching itself in compute using fetch function.
 * @param req The incoming request
 */
function detectUpstreamRequestLoop(req) {
    var _a;
    // Capture the original Via header in the cloud,
    // so we can track the request path through the system and detect loops.
    // Locally, it's just set to 'Edgio Core' by default.
    if (!(0, environment_1.isLocal)()) {
        serverMetrics_1.metrics.via = ((_a = req.getHeader(constants_1.HTTP_HEADERS.via)) === null || _a === void 0 ? void 0 : _a.toString()) || serverMetrics_1.metrics.via;
    }
    // Detect loops in the request path using the Via header.
    // It needs to be here and not in ModProxyCore,
    // because customers can still fetch itself in compute using fetch function,
    // in Next.js app etc... through the permalink URL, localhost...
    const edgioCoreCount = serverMetrics_1.metrics.via.split(constants_1.EDGIO_VIA_HEADER_VALUE).length - 1;
    if (edgioCoreCount > constants_1.EDGIO_MAX_NESTED_REQUESTS) {
        throw new EdgioProjectRequestLoopError_1.EdgioProjectRequestLoopError();
    }
}
